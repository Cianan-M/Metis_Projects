{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scraping and Cleaning for NBA Player Data\n",
    "\n",
    "    Goal: Get a list of players who have played in the NBA,\n",
    "          look at their performance through their first two seasons\n",
    "          and see how old they were\n",
    "    \n",
    "    1. Get NBA advanced metric data from 2000-2019 for every player within that period\n",
    "    2. Clean data so that those who played before 2000 season are removed\n",
    "    3. Clean data so only players whose careers have finished are still present\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Goes through data tables when web scraping and pulls all player data \n",
    "rows is defind in get_data which is where the scraping of our website occurs\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def table_read(rows):\n",
    "    data = []\n",
    "    intermediate_list = []\n",
    "\n",
    "    for tr in rows:\n",
    "        for td in tr.findAll(\"td\"):\n",
    "            text = td(string=True)\n",
    "            intermediate_list.append(''.join(text) if text else '0.0')\n",
    "        data.append(intermediate_list)\n",
    "        intermediate_list = []\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Merges data pulled from table_read and puts it into a dictionary with headers\n",
    "\"\"\"\n",
    "\n",
    "def dict_creation(data):\n",
    "    headers = ['Player','Position','Age','Team','Games_played',\n",
    "               'Min_per_game','PER', 'TS%',\n",
    "               '3PAr', 'FTr','ORB%','DRB%',\n",
    "               'TRB%','AST%','STL%','BLK%',\n",
    "               'TOV%','USG%','', 'OWS',\n",
    "               'DWS','WS','WS/48','', \n",
    "               'OBPM','DBPM','BPM','VORP']\n",
    "\n",
    "    data_with_headers = []\n",
    "    for i in range(len(data)):\n",
    "        data_dict = dict(zip(headers, data[i]))\n",
    "        data_with_headers.append(data_dict)\n",
    "    return(data_with_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is were the web scraping done\n",
    "\n",
    "NBA_year is a list of the years to pull get data from\n",
    "url is the url of the website to scrape\n",
    "table_name and table_id are the html markers for the table that is being scraped \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_data(NBA_years, url, table_name, table_id):\n",
    "    #url = 'https://www.basketball-reference.com/leagues/NBA_{}_per_game.html'\n",
    "    df_NBA = []\n",
    "    for year in NBA_years:\n",
    "        # year is insert into url so that we target the year we want in our website\n",
    "        file_url = url.format(year) \n",
    "        \n",
    "        response = requests.get(file_url)\n",
    "        page = response.text\n",
    "        NBA_soup = BeautifulSoup(page, 'lxml')\n",
    "        table = NBA_soup.find(class_= table_name, id = table_id)\n",
    "        \n",
    "        \n",
    "        rows = table.findAll('tr')\n",
    "        \n",
    "        # Here we call on our functions created above \n",
    "        data = table_read(rows)\n",
    "        table_creation = dict_creation(data)\n",
    "    \n",
    "        dfs = pd.DataFrame(table_creation)\n",
    "        dfs['Year'] = year # adds what year the data is pulled from to our table\n",
    "        dfs = dfs[1:] # first row in all the tables for Baketball refernce are empty, this sorts them out\n",
    "        \n",
    "        # Removes duplicate entries \n",
    "        dfs = dfs.drop_duplicates(subset='Player', keep='first')\n",
    "        dfs = dfs.reset_index()\n",
    "        df_NBA.append(dfs)\n",
    "        \n",
    "    # This combines all dataframes\n",
    "    return pd.concat(df_NBA).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBA_years = [2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010,\n",
    "            2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018]\n",
    "\n",
    "url ='https://www.basketball-reference.com/leagues/NBA_{}_advanced.html'\n",
    "table_name = 'overthrow table_container' \n",
    "table_id = 'div_advanced_stats'\n",
    "df_advanced_stats = get_data(NBA_years, url, table_name, table_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This Data is pulled to remove any players who were active before 2000 \n",
    "and are still active players today from the dataframe, to get an accurate count \n",
    "of a players career length and first 2 year performance \n",
    "\"\"\"\n",
    "NBA_years = [1999, 2019]\n",
    "url = 'https://www.basketball-reference.com/leagues/NBA_{}_per_game.html'\n",
    "table_name = 'stats_table'\n",
    "table_id = 'per_game_stats'\n",
    "sorted_players_df = get_data(NBA_years, url, table_name, table_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing Age and Win shares to floats so we can work with them later\n",
    "df_advanced_stats[['Age','WS']] = df_advanced_stats[['Age','WS']].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes * from some player names\n",
    "df_advanced_stats['Player'] = df_advanced_stats[\"Player\"].str.replace(\"*\", \"\")\n",
    "df_advanced_stats.dropna(axis = 'rows', inplace =True)\n",
    "#sorts dataframe by age and Player name\n",
    "df_advanced_stats = df_advanced_stats.sort_values(['Player','Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creates 4 lists that will be added to dataframe:\n",
    "    Win Share in first 2 years\n",
    "    Career length\n",
    "    Age entering the NBA\n",
    "    Age of retirement \n",
    "\"\"\"\n",
    "\n",
    "ws_12 = []\n",
    "career_len = []\n",
    "max_age = []\n",
    "enter_age = []\n",
    "\n",
    "for count, player in enumerate(df_advanced_stats.Player):\n",
    "    df1 = df_advanced_stats[df_advanced_stats['Player']==player]\n",
    "    df1.reset_index(inplace = True)\n",
    "    clen = df1.shape[0]\n",
    "    if clen >= 2:\n",
    "        ws = (df1.loc[0][23] + df1.loc[1][23])/2\n",
    "        old_age = df1.loc[clen-1][4]\n",
    "        young_age = df1.loc[0][4]\n",
    "    else:\n",
    "        ws = 0\n",
    "        age = 0\n",
    "        age1= 0\n",
    "    max_age.append(old_age)\n",
    "    career_len.append(clen)\n",
    "    ws_12.append(float(ws))\n",
    "    enter_age.append(young_age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adds list to dataframe\n",
    "df_advanced_stats['Career_length'] = career_len\n",
    "df_advanced_stats['Retirement_age'] = max_age\n",
    "df_advanced_stats['WS_first_2yr'] = ws_12\n",
    "df_advanced_stats['Age_yr1'] = enter_age\n",
    "df_advanced_stats['Career_length'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = ['LeBron James','Dwyane Wade','Darko Miličić','Maciej Lampe','Brandon Hunter']\n",
    "\n",
    "player_stats = []\n",
    "for player in test_set:\n",
    "    df_holder = df_advanced_stats[df_advanced_stats['Player']==player]\n",
    "    player_stats.append(df_holder)\n",
    "\n",
    "df_example_players = pd.concat(player_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4414, 33)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Removes NBA players who were active before 2000s from dataframe\n",
    "and NBA Players who are currently active\n",
    "and removes players who only spent 1 year in the NBA\n",
    "\"\"\"\n",
    "\n",
    "sorted_players = sorted_players_df.Player.unique()\n",
    "\n",
    "rows_to_remove = []\n",
    "for player in sorted_players:\n",
    "    #filter1 = dfr['Player'].isin(player)\n",
    "    df_holder = df_advanced_stats[df_advanced_stats['Player']==player]\n",
    "    rows_to_remove.append(df_holder)\n",
    "    \n",
    "df_of_removed_players = pd.concat(rows_to_remove)\n",
    "df_of_1yr_players = df_advanced_stats[df_advanced_stats['Career_length'] == 1]\n",
    "\n",
    "df_advanced_stats_sorted = pd.concat([df_advanced_stats, df_of_removed_players, \n",
    "                                      df_of_1yr_players]).drop_duplicates(keep=False)\n",
    "df_advanced_stats_sorted.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removes outliers early code doesn't catch \n",
    "outlier_remove = df_advanced_stats_sorted[df_advanced_stats_sorted['Age_yr1'] > 29]\n",
    "df_advanced_stats_sorted = pd.concat([df_advanced_stats_sorted, outlier_remove, a ]).drop_duplicates(keep=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving dataframe with pickle\n",
    "\n",
    "with open('df_advanced_stats.pickle', 'wb') as handle:\n",
    "    pickle.dump(df_advanced_stats_sorted, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('example_players', 'wb') as handle:\n",
    "    pickle.dump(df_example_players, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
