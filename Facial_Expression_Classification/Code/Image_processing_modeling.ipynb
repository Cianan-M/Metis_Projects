{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing and Modeling \n",
    "\n",
    "### Goal: Use machine learning to predict facial expressions \n",
    "\n",
    "    Objectives:\n",
    "    1) Read image data and store in dataframe \n",
    "    2) Reduce size of images and grayscale to lower data points\n",
    "    3) Try to isolate humna face\n",
    "    4) Run three classification models: \n",
    "        - Random Forest\n",
    "        - XGClassifier\n",
    "        - Support vector machine\n",
    "    5) See whether data augmentation has any positive affect on the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.filters import prewitt_h,prewitt_v\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import random\n",
    "from scipy import ndarray\n",
    "import skimage as sk\n",
    "from skimage import transform\n",
    "from skimage import util\n",
    "\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe Creation\n",
    "\n",
    "    Reading Image Directory and Info into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Data is broken down into 2 groups, each with 35 male and 35 female particpants\n",
    "# Each particpant make 7 different facial expresions, and have 5 different head angles \n",
    "# for each expression ranging from 90 degress to the left to 90 degress to the right\n",
    "\n",
    "# Each image file is marked with each of the following catergories\n",
    "# These lists are created to loop through the image names and create a dataframe from them\n",
    "Group = ['A','B']\n",
    "Gender = ['F','M']\n",
    "Identity = ['01','02','03','04','05','06','07','08','09','10',\n",
    "            '11','12','13','14','15','16','17','18','19','20',\n",
    "            '21','22','23','24','25','26','27','28','29','30',\n",
    "            '31','32','33','34','35']\n",
    "Expression = ['AF','AN','DI','HA','NE','SA','SU']\n",
    "Angle = ['FL','HL','S','HR','FR']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looping through all files to create a dataframe\n",
    "\n",
    "compile_list = []\n",
    "\n",
    "for group in Group:\n",
    "    for gender in Gender:\n",
    "        for identity in Identity:\n",
    "            for expression in Expression:\n",
    "                for angle in Angle:\n",
    "                    # file is directory of image, use format in combination with the loops to call upon \n",
    "                    # every image file\n",
    "                    file = \"/Users/Cianan/Downloads/KDEF_and_AKDEF/KDEF/{}{}{}/{}{}{}{}{}.JPG\"\n",
    "                    stitch_file = file.format(group,gender,identity,\n",
    "                                              group,gender,identity,\n",
    "                                              expression,angle)\n",
    "                    # pic iden is a list created to store all info about a given image\n",
    "                    pic_iden = [group,gender,identity,expression,angle,stitch_file]\n",
    "                    compile_list.append(pic_iden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Identity</th>\n",
       "      <th>Expression</th>\n",
       "      <th>Head_Angle</th>\n",
       "      <th>Image_Directory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>01</td>\n",
       "      <td>AF</td>\n",
       "      <td>FL</td>\n",
       "      <td>/Users/Cianan/Downloads/KDEF_and_AKDEF/KDEF/AF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>01</td>\n",
       "      <td>AF</td>\n",
       "      <td>HL</td>\n",
       "      <td>/Users/Cianan/Downloads/KDEF_and_AKDEF/KDEF/AF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>01</td>\n",
       "      <td>AF</td>\n",
       "      <td>S</td>\n",
       "      <td>/Users/Cianan/Downloads/KDEF_and_AKDEF/KDEF/AF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>01</td>\n",
       "      <td>AF</td>\n",
       "      <td>HR</td>\n",
       "      <td>/Users/Cianan/Downloads/KDEF_and_AKDEF/KDEF/AF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>01</td>\n",
       "      <td>AF</td>\n",
       "      <td>FR</td>\n",
       "      <td>/Users/Cianan/Downloads/KDEF_and_AKDEF/KDEF/AF...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Group Gender Identity Expression Head_Angle  \\\n",
       "0     A      F       01         AF         FL   \n",
       "1     A      F       01         AF         HL   \n",
       "2     A      F       01         AF          S   \n",
       "3     A      F       01         AF         HR   \n",
       "4     A      F       01         AF         FR   \n",
       "\n",
       "                                     Image_Directory  \n",
       "0  /Users/Cianan/Downloads/KDEF_and_AKDEF/KDEF/AF...  \n",
       "1  /Users/Cianan/Downloads/KDEF_and_AKDEF/KDEF/AF...  \n",
       "2  /Users/Cianan/Downloads/KDEF_and_AKDEF/KDEF/AF...  \n",
       "3  /Users/Cianan/Downloads/KDEF_and_AKDEF/KDEF/AF...  \n",
       "4  /Users/Cianan/Downloads/KDEF_and_AKDEF/KDEF/AF...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe is created\n",
    "image_df = pd.DataFrame(compile_list, columns = ['Group','Gender',\n",
    "                                                 'Identity','Expression',\n",
    "                                                 'Head_Angle','Image_Directory'])\n",
    "image_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are some images that are of unequal size or that are missing\n",
    "# this is used to sort that out \n",
    "\n",
    "bad_data = []\n",
    "for count in range(image_df.shape[0]):\n",
    "    image = cv2.imread(image_df.Image_Directory[count])\n",
    "    # try statement cathes missing images\n",
    "    try: \n",
    "        # if statement catches images that arent 781 by 581\n",
    "        if len(image) != 762:\n",
    "            bad_data.append(count)\n",
    "    except:\n",
    "        bad_data.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes all missing images and images of differnt size from dataframe\n",
    "# there is only 4 images being sorted out\n",
    "image_sorted = image_df.drop(bad_data).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image = cv2.imread(image_df.Image_Directory[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image feature selection and Variable Creation for machine learning models\n",
    "\n",
    "    - Creating dependent and independent variables for train test\n",
    "    - Processing images so that they can be read by our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating y variables\n",
    "# changing from string to int so that they can be processed by XGClassifier\n",
    "dependent = []\n",
    "\n",
    "for i in range(len(image_sorted)):\n",
    "    if image_sorted.Expression[i] == 'AF':\n",
    "        dependent.append(0)\n",
    "    elif image_sorted.Expression[i] == 'AN':\n",
    "        dependent.append(1)\n",
    "    elif image_sorted.Expression[i] == 'DI':\n",
    "        dependent.append(2)\n",
    "    elif image_sorted.Expression[i] == 'HA':\n",
    "        dependent.append(3)\n",
    "    elif image_sorted.Expression[i] == 'NE':\n",
    "        dependent.append(4)\n",
    "    elif image_sorted.Expression[i] == 'SA':\n",
    "        dependent.append(5)\n",
    "    elif image_sorted.Expression[i] == 'SU':\n",
    "        dependent.append(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating x variables\n",
    "\n",
    "independent = []\n",
    "for i in range(len(image_sorted)):\n",
    "    # reads image and grayscales, so each pixel goes from an array of 3 to 1\n",
    "    image = cv2.imread(image_sorted.Image_Directory[i],cv2.IMREAD_GRAYSCALE)\n",
    "    # reduces size of image fro, 562x762 to 281x381 reducing the number of pixel by 4\n",
    "    img = cv2.resize(image, (281, 381))\n",
    "    # croping sides of image that are empty space, so just the face is showing\n",
    "    crop = iaa.Crop(px=(30))\n",
    "    img = crop.augment_image(img)\n",
    "    img = img.T\n",
    "    # turns to 1D array so the models can process the image\n",
    "    img = img.ravel()\n",
    "    independent.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nscale changes the scale of the x and y axis by some number scalar between 1.5 and 1 \\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are functoins created for the purpose of Data Augmentation \n",
    "\n",
    "def rotation(img):\n",
    "    rot_deg = random.uniform(-30, 30)\n",
    "    img1 = sk.transform.rotate(img, rot_deg)\n",
    "    return img1\n",
    "\n",
    "\"\"\"\n",
    "Rotation introduces a random rotation from -30 to 30 degress into the image\n",
    "\"\"\"\n",
    "    \n",
    "def noise(img):\n",
    "    img1 = sk.util.random_noise(img)\n",
    "    return img1\n",
    "    \n",
    "\"\"\"\n",
    "Noise introduces random noise into the image\n",
    "\"\"\"\n",
    "    \n",
    "def flip(img):\n",
    "    flip_hr=iaa.Flipud(p=1.0)\n",
    "    img1= flip_hr.augment_image(img)\n",
    "    return img1\n",
    "\n",
    "\"\"\"\n",
    "Flip cuases the image to flip upside down\n",
    "\"\"\"\n",
    "\n",
    "def scale(img):\n",
    "    scale_im=iaa.Affine(scale={\"x\": (1.5, 1.0), \"y\": (1.5, 1.0)})\n",
    "    img1 =scale_im.augment_image(img)\n",
    "    return img1\n",
    "\n",
    "\"\"\"\n",
    "scale changes the scale of the x and y axis by some number scalar between 1.5 and 1 \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits data into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(independent, dependent,test_size=0.2, random_state=42)\n",
    "\n",
    "# used to save train and test sets for use in other notebooks\n",
    "\n",
    "# pickle.dump(x_train, open('x_trainc', 'wb'))\n",
    "# pickle.dump(x_test, open('x_testc', 'wb'))\n",
    "# pickle.dump(y_train, open('y_trainc', 'wb'))\n",
    "# pickle.dump(y_test, open('y_testc', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107061"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models_scores(metric, data_aug, identifer, x_train, y_train, x_test, y_test):\n",
    "    \n",
    "    # Checks if i want to use data augmentation\n",
    "    if data_aug == 'yes':\n",
    "        for i in range(len(x_train)):\n",
    "            # reshapes array from 1d to 2d so that I can apply changes to image\n",
    "            img = np.reshape(x_train[i], (281, 381))\n",
    "            # randomly chooses function to transform image\n",
    "            key = random.choice([rotation, scale, flip, noise])\n",
    "            image = key(img)\n",
    "            image = image.T\n",
    "            image = image.ravel()\n",
    "            x_train.append(image)\n",
    "        # this is for later in the code so that y_train doesnt double in size \n",
    "        # every time data augmentation is used\n",
    "        reshape_y = len(y_train)\n",
    "        y_train = y_train + y_train   \n",
    "    \n",
    "    if metric == 'xgb': # runs XGClassifier\n",
    "        \n",
    "        # XGC needs data to be in an array \n",
    "        y_train = np.array(y_train)\n",
    "        y_test = np.array(y_test)\n",
    "        x_train = np.array(x_train)\n",
    "        x_test = np.array(x_test)\n",
    "        \n",
    "        boost = XGBClassifier(XGBClassifier(max_depth=4, learning_rate=0.8, n_estimators=100, \n",
    "                                            objective=\"multi:softprob\", verbose = 1))\n",
    "        \n",
    "        eval_set = [(x_train,y_train),(x_test,y_test)] \n",
    "        results = boost.fit(x_train, y_train, eval_set = eval_set, verbose=True, early_stopping_rounds=5)\n",
    "        \n",
    "    elif metric == 'rf': # runs random forest\n",
    "        \n",
    "        rfc = RandomForestClassifier(n_estimators = 400, max_features= 'sqrt', random_state = 42, verbose = 1,n_jobs=-1)\n",
    "        results = rfc.fit(x_train, y_train)\n",
    "        accuracy = accuracy_score(results.predict(x_test), y_test)\n",
    "        return('Accuracy:', accuracy) \n",
    "        \n",
    "    elif metric == 'svm': # runs support vector machine\n",
    "        \n",
    "        lin_svm = svm.NuSVC(random_state = 42, verbose = 1, probability = True)\n",
    "        results = lin_svm.fit(x_train,y_train)\n",
    "        accuracy = accuracy_score(results.predict(x_test), y_test)\n",
    "        return('Accuracy:', accuracy)\n",
    "    \n",
    "    if data_aug == 'yes': # reset y_train to original length\n",
    "        del y_train[-n:]\n",
    "\n",
    "    # creates filename and saves model \n",
    "    file = metric + '_' + data_aug + '_' + identifer\n",
    "    pickle.dump(results, open(file, 'wb'))\n",
    "    \n",
    "    \"\"\"\n",
    "    Function specifies what model I want to run, whether or not I want to use data augmentation\n",
    "    and saves the model when done \n",
    "    \"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   27.3s\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:   59.7s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 400 out of 400 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Accuracy:', 0.610204081632653)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "When using model scoresThe first input is \n",
    "    'rf' if you want random forest\n",
    "    'xgb' if you want XGClassifier\n",
    "    'svm' if you want support vector machine\n",
    "    \n",
    "Second input can be 'yes' if you want data augmentation\n",
    "    or anything else if you don't but 'no' is prefered for naming convention\n",
    "    \n",
    "Third input is used at the end of the file name to the model when its going to be saved,\n",
    "so if you make a change you can put 'no crop' \n",
    "\n",
    "The last four inputs are just the training and test data but these dont need to be touched\n",
    "\"\"\"\n",
    "\n",
    "models_scores('rf', 'no', 'crop4_cv', x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_leaf': 4, 'min_samples_split': 5}\n"
     ]
    }
   ],
   "source": [
    "# Uses grid search to find best models\n",
    "rfc = RandomForestClassifier(n_jobs=-1,max_features= 'sqrt' ,n_estimators=100, oob_score = True, min_samples_split = 2, min_samples_leaf = 1 ) \n",
    "\n",
    "param_grid = { \n",
    "    'min_samples_split': [5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4]\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(x_train, y_train)\n",
    "print(CV_rfc.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to test different hyperparameters for XGClassifier\n",
    "xgb = XGBClassifier(max_depth=4, learning_rate=0.8, n_estimators=100, objective=\"multi:softprob\", verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:22:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-merror:0.45735\tvalidation_1-merror:0.58163\n",
      "Multiple eval metrics have been passed: 'validation_1-merror' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-merror hasn't improved in 5 rounds.\n",
      "[1]\tvalidation_0-merror:0.35010\tvalidation_1-merror:0.55816\n",
      "[2]\tvalidation_0-merror:0.26379\tvalidation_1-merror:0.53061\n",
      "[3]\tvalidation_0-merror:0.20352\tvalidation_1-merror:0.50510\n",
      "[4]\tvalidation_0-merror:0.15424\tvalidation_1-merror:0.48775\n",
      "[5]\tvalidation_0-merror:0.12283\tvalidation_1-merror:0.48571\n",
      "[6]\tvalidation_0-merror:0.09091\tvalidation_1-merror:0.45510\n",
      "[7]\tvalidation_0-merror:0.06665\tvalidation_1-merror:0.44286\n",
      "[8]\tvalidation_0-merror:0.04648\tvalidation_1-merror:0.44184\n",
      "[9]\tvalidation_0-merror:0.03141\tvalidation_1-merror:0.44490\n",
      "[10]\tvalidation_0-merror:0.01966\tvalidation_1-merror:0.43163\n",
      "[11]\tvalidation_0-merror:0.01328\tvalidation_1-merror:0.41633\n",
      "[12]\tvalidation_0-merror:0.00843\tvalidation_1-merror:0.40816\n",
      "[13]\tvalidation_0-merror:0.00460\tvalidation_1-merror:0.40102\n",
      "[14]\tvalidation_0-merror:0.00204\tvalidation_1-merror:0.39694\n",
      "[15]\tvalidation_0-merror:0.00128\tvalidation_1-merror:0.39898\n",
      "[16]\tvalidation_0-merror:0.00102\tvalidation_1-merror:0.39490\n",
      "[17]\tvalidation_0-merror:0.00102\tvalidation_1-merror:0.39592\n",
      "[18]\tvalidation_0-merror:0.00102\tvalidation_1-merror:0.39796\n",
      "[19]\tvalidation_0-merror:0.00102\tvalidation_1-merror:0.39388\n",
      "[20]\tvalidation_0-merror:0.00102\tvalidation_1-merror:0.39490\n",
      "[21]\tvalidation_0-merror:0.00077\tvalidation_1-merror:0.40612\n",
      "[22]\tvalidation_0-merror:0.00077\tvalidation_1-merror:0.39490\n",
      "[23]\tvalidation_0-merror:0.00077\tvalidation_1-merror:0.39082\n",
      "[24]\tvalidation_0-merror:0.00077\tvalidation_1-merror:0.38571\n",
      "[25]\tvalidation_0-merror:0.00077\tvalidation_1-merror:0.38367\n",
      "[26]\tvalidation_0-merror:0.00077\tvalidation_1-merror:0.38061\n",
      "[27]\tvalidation_0-merror:0.00077\tvalidation_1-merror:0.37959\n",
      "[28]\tvalidation_0-merror:0.00077\tvalidation_1-merror:0.37959\n",
      "[29]\tvalidation_0-merror:0.00077\tvalidation_1-merror:0.37449\n",
      "[30]\tvalidation_0-merror:0.00077\tvalidation_1-merror:0.36939\n",
      "[31]\tvalidation_0-merror:0.00077\tvalidation_1-merror:0.36939\n",
      "[32]\tvalidation_0-merror:0.00077\tvalidation_1-merror:0.36123\n",
      "[33]\tvalidation_0-merror:0.00077\tvalidation_1-merror:0.36224\n",
      "[34]\tvalidation_0-merror:0.00077\tvalidation_1-merror:0.36429\n",
      "[35]\tvalidation_0-merror:0.00077\tvalidation_1-merror:0.35918\n",
      "[36]\tvalidation_0-merror:0.00077\tvalidation_1-merror:0.35918\n",
      "[37]\tvalidation_0-merror:0.00077\tvalidation_1-merror:0.35102\n",
      "[38]\tvalidation_0-merror:0.00077\tvalidation_1-merror:0.35408\n",
      "[39]\tvalidation_0-merror:0.00077\tvalidation_1-merror:0.35510\n",
      "[40]\tvalidation_0-merror:0.00077\tvalidation_1-merror:0.35510\n",
      "[41]\tvalidation_0-merror:0.00077\tvalidation_1-merror:0.36123\n",
      "[42]\tvalidation_0-merror:0.00077\tvalidation_1-merror:0.35102\n",
      "Stopping. Best iteration:\n",
      "[37]\tvalidation_0-merror:0.00077\tvalidation_1-merror:0.35102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_set=[(np.array(x_train),np.array(y_train)),(np.array(x_test),np.array(y_test))] #tracking train/validation error as we go\n",
    "dok = xgb.fit(np.array(x_train), np.array(y_train),eval_set = eval_set, verbose=True, early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import BatchNormalization, Flatten\n",
    "\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 6 6 6]\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "['AF']\n"
     ]
    }
   ],
   "source": [
    "#image_sorted.Expression\n",
    "# define example\n",
    "values = array(image_sorted.Expression)\n",
    "#print(values)\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print(integer_encoded)\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(onehot_encoded)\n",
    "# invert first example\n",
    "inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
    "print(inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(independent, onehot_encoded,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# hidden layer\n",
    "# model.add(Conv2D(32, kernel_size = (3, 3), activation='relu', input_shape=(107061,1)))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(10000, input_shape=(107061,), activation='relu'))\n",
    "model.add(Dense(10000, activation='relu'))\n",
    "# output layer\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 10000)             1070620000\n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10000)             100010000 \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 7)                 70007     \n",
      "=================================================================\n",
      "Total params: 1,170,700,007\n",
      "Trainable params: 1,170,700,007\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "# training the model for 10 epochs\n",
    "x_test1= np.array(x_test)\n",
    "y_test1= np.array(y_test)\n",
    "x_train1= np.array(x_train)\n",
    "y_train1= np.array(y_train)\n",
    "\n",
    "# y_train1 = tf.keras.utils.to_categorical(y_train1, 7)\n",
    "# y_test1 = tf.keras.utils.to_categorical(y_test1, 7)\n",
    "# x_train1 = tf.keras.utils.to_categorical(y_train1, 7)\n",
    "# x_test1 = tf.keras.utils.to_categorical(y_test1, 7)\n",
    "model.fit(x_train1, y_train1, epochs=20, validation_data=(x_test1, y_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
